{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb32d211-8429-4fe1-b0a1-f12131e478ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets transformers\n",
    "# !pip install datasets --upgrade (otherwise issues to load the bean dataset)\n",
    "# installations\n",
    "# !pip install matplotlib\n",
    "# !pip install pillow\n",
    "# !pip install tifffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19487d13-2f13-48f0-bbf3-970748deb300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run once, unless you have any update for the data structure\n",
    "# create files with 47 channels at folder csiseminar/project/dataset/47_channels/\n",
    "# the output is relevant to check that the files are not only zeros (viewing them, it looks like \n",
    "# it is only grey\n",
    "# %run preprocess_tif_data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "529bb5ee-8ea5-4955-a341-adff3df49a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eilaarich-landkof-stanford/miniconda3/envs/transformers/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from transformers.utils.dummy_vision_objects import ImageGPTFeatureExtractor\n",
    "import random\n",
    "from PIL import ImageDraw, ImageFont, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b8402e5-9441-49dc-9bbc-b2bcc0d5f902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path_to_non_progressors_images = \"/Users/eilaarich-landkof-stanford/Documents/Code/csiseminar/project/dataset/47_channels/labels/nonprogressor/\"\n",
    "path_to_progressors_images = \"/Users/eilaarich-landkof-stanford/Documents/Code/csiseminar/project/dataset/47_channels/labels/progressor/\"\n",
    "CHANNELS = 47\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "400f877d-acfc-48bc-9061-3d8ed9ca7515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n",
      "Image shape: (47, 1024, 1024)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "%run prepare_dataset_from_image_files.ipynb\n",
    "non_progressors_images_list = os.listdir(path_to_non_progressors_images)\n",
    "progressors_images_list = os.listdir(path_to_progressors_images)\n",
    "non_progressors_images_list = [os.path.join(path_to_non_progressors_images,x) for x in non_progressors_images_list]\n",
    "progressors_images_list = [os.path.join(path_to_progressors_images,x) for x in progressors_images_list]\n",
    "\n",
    "\n",
    "non_progressors_images_dict = load_47_channel_tif_to_dataset_object(non_progressors_images_list,\"nonprogressor\")\n",
    "progressors_images_dict = load_47_channel_tif_to_dataset_object(progressors_images_list,\"progressor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c628b9a-0cc9-4932-acce-f23a6ab53659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# progressors_images_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e054908d-860e-49af-8a8d-a2c2e1cf42a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dataset object using Dataset.from_dict\n",
    "%run prepare_dataset_from_image_files.ipynb\n",
    "dataset_prog = Dataset.from_dict(progressors_images_dict) #,features={\"image\": \"image\", \"labels\": class_label})\n",
    "dataset_non_prog = Dataset.from_dict(non_progressors_images_dict) #,features={\"image\": \"image\", \"labels\": class_label})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcd935a1-fa6b-42e2-89af-57f9dfd39905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'labels'],\n",
       "    num_rows: 44\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_non_prog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6d9ab86-25a5-4a58-9277-3d9ddc6e6087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset_non_prog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "162529b7-e48b-403d-8884-de81b3da1e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, concatenate_datasets\n",
    "from datasets import DatasetDict\n",
    "\n",
    "\n",
    "# Concatenate the datasets\n",
    "ds = concatenate_datasets([dataset_prog, dataset_non_prog])\n",
    "# 90% train, 10% test + validation - CAN BE CHANGED\n",
    "train_testvalid = ds.train_test_split(test_size=0.1)\n",
    "# Split the 10% test + valid in half test, half valid\n",
    "test_valid = train_testvalid['test'].train_test_split(test_size=0.5)\n",
    "train_test_valid_dataset = DatasetDict({\n",
    "    'train': train_testvalid['train'],\n",
    "    'test':  test_valid['test'],\n",
    "    'valid': test_valid['train']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb63030b-c46d-45a8-978c-e35e059f1ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'labels'],\n",
       "        num_rows: 52\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['image', 'labels'],\n",
       "        num_rows: 3\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['image', 'labels'],\n",
       "        num_rows: 3\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2dbfcc4-a4b4-48a9-8ab5-6b1d052ad1ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'labels'],\n",
       "    num_rows: 52\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_valid_dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45a158d4-6cc2-4acf-96ca-359799b8ded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the feature extractor \n",
    "from transformers import ViTFeatureExtractor\n",
    "\n",
    "model_name_or_path = 'google/vit-base-patch16-224-in21k'\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(model_name_or_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80d5b2d4-8ad3-41fc-a113-76584b3ffec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViTFeatureExtractor {\n",
       "  \"do_normalize\": true,\n",
       "  \"do_rescale\": true,\n",
       "  \"do_resize\": true,\n",
       "  \"image_mean\": [\n",
       "    0.5,\n",
       "    0.5,\n",
       "    0.5\n",
       "  ],\n",
       "  \"image_processor_type\": \"ViTFeatureExtractor\",\n",
       "  \"image_std\": [\n",
       "    0.5,\n",
       "    0.5,\n",
       "    0.5\n",
       "  ],\n",
       "  \"resample\": 2,\n",
       "  \"rescale_factor\": 0.00392156862745098,\n",
       "  \"size\": {\n",
       "    \"height\": 224,\n",
       "    \"width\": 224\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12305200-f0cb-4361-a423-26f7818dac50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_valid_dataset['train']['image']\n",
    "# accessing one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddcfe4c2-f276-480d-a636-613f0112896f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'labels'],\n",
       "    num_rows: 52\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming you have loaded your train dataset as train_dataset\n",
    "train_dataset = train_test_valid_dataset['train']\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b01ba1a0-a82b-4f41-917f-a338cef0a322",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Choose an index to access a specific image\n",
    "index = 0  # Change this to the desired index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c82a0bc-2a78-49c0-bfaf-5da9fc235d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the image data and label at the chosen index\n",
    "# image_data = train_dataset['image'][index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264a9e14-dc2b-4f27-83d1-825513a2c590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d2c559-de71-420c-8a4c-75b2f3407b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = train_dataset['Labels'][index]\n",
    "labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c86287-205b-49cf-ad46-45e58279cf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Print information about the image\n",
    "print(\"Image shape:\", image_data.shape)\n",
    "print(\"labels:\", labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765d9020-3496-4ce6-a072-beaaa9430c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(feature_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b5680348-97c7-4ca2-b398-7e3e2a92604c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try the feature_extractor on this image\n",
    "feature_extractor(image_data, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1768dde-7d1d-46c0-8198-2ad1ed1b106f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_extractor(train_split[, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55058b8-8e9a-4168-9499-8da75eccd144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_example(example):\n",
    "#     inputs = feature_extractor(example['image'], return_tensors='pt')\n",
    "#     inputs['labels'] = example['labels']\n",
    "#     return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6eda27-0fe5-4cde-b273-fcdbcb11110e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
