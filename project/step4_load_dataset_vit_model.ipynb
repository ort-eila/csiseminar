{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ort-eila/csiseminar/blob/main/project/step4_load_dataset_vit_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "OldUIqyzUm8d"
   },
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install --upgrade transformers\n",
    "# !pip install datasets\n",
    "# !pip install --upgrade datasets\n",
    "\n",
    "# # for CPU:\n",
    "# !pip install transformers[torch]\n",
    "# # restart\n",
    "# !pip install tensorboard\n",
    "# !conda install pytorch torchvision torchaudio cudatoolkit=11.1 -c pytorch -c conda-forge\n",
    "# !conda install scikit-learn\n",
    "# pip install transformers[torch]\n",
    "# conda install transformers pytorch -c conda-forge -c pytorch\n",
    "# pip install accelerate -U\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "OWupabIrDMED",
    "outputId": "02db6920-dbd1-43c8-bec7-38b0806a1d85"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/eilaarich-landkof-stanford/Documents/Code/csiseminar/project'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgb_images_path = \"\"\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /Users/eilaarich-landkof-stanford/Downloads/train_validation_test_2023_08_14_20_18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YVN2-UK1DOvS",
    "outputId": "27d8d37d-970c-41a7-e8e5-7c1994a60fff"
   },
   "outputs": [],
   "source": [
    "if \"eilaarich-landkof-stanford\" in os.getcwd():\n",
    "    rgb_images_path = os.path.join(\"/Users/eilaarich-landkof-stanford/Downloads/train_validation_test_2023_08_14_20_18/\")\n",
    "else:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/gdrive\")\n",
    "    rgb_images_path = \"/content/gdrive/MyDrive/Seminar/project/immune_310_project/dataset/JPG_VECT_TO_IMG_224_224/train_validation_test_2023_08_14_20_18\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XdaEVkvJbAVG",
    "outputId": "8299540e-7a61-401e-ff07-b6c66192e0d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets version: 2.14.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eilaarich-landkof-stanford/miniconda3/envs/transformers/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "print(\"datasets version:\", datasets.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "136y8YShdzqg"
   },
   "outputs": [],
   "source": [
    "from datasets import ClassLabel\n",
    "\n",
    "class_labels = ClassLabel(names=[\"nonprogressor\", \"progressor\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xvBd6fc9a4Jd",
    "outputId": "b5b22ccb-4380-40c4-c812-140034bba6ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds_with_pil_images_fld is /Users/eilaarich-landkof-stanford/Downloads/train_validation_test_2023_08_14_20_18/ds_with_pil_images/train\n",
      "Datasets saved to disk with PIL images.  train\n",
      "ds_with_pil_images_fld is /Users/eilaarich-landkof-stanford/Downloads/train_validation_test_2023_08_14_20_18/ds_with_pil_images/validation\n",
      "Datasets saved to disk with PIL images.  validation\n",
      "ds_with_pil_images_fld is /Users/eilaarich-landkof-stanford/Downloads/train_validation_test_2023_08_14_20_18/ds_with_pil_images/test\n",
      "Datasets saved to disk with PIL images.  test\n"
     ]
    }
   ],
   "source": [
    "from datasets.io.abc import Dataset\n",
    "\n",
    "ds={}\n",
    "for val in [\"train\",\"validation\",\"test\"]:\n",
    "  ds_with_pil_images_fld = os.path.join(rgb_images_path,'ds_with_pil_images',val)   # Output metadata JSON file name\n",
    "  print(\"ds_with_pil_images_fld is {}\".format(ds_with_pil_images_fld))\n",
    "  ds[val] = Dataset.load_from_disk(ds_with_pil_images_fld)\n",
    "  print(\"Datasets saved to disk with PIL images. \",val)\n",
    "# will be used by step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105,
     "referenced_widgets": [
      "5cffb7213aa546eb8b976a32b2b2573f",
      "3377058e433b4fa9a08b58c6bd50d37e",
      "57ae87708adf4568aa754f712abd4290",
      "edb9e3aaf4414993a323284758afd5ed",
      "2f08a82ee9954559a8d33b7ea328691f",
      "d97ec4ab607e4f18b02ce5552227ba7b",
      "ba58cb5ee22147bda7f3de33fe53a997",
      "7aed4615ee9e4830aa18f7ff38ad5c3e",
      "d1e0e92df70242408234c38ec0522452",
      "7bb5710864e34c399a31d067d493eca5",
      "bef3d30a0d7a41be8b0292e9fce2d6d2"
     ]
    },
    "id": "n_Q_au_o7x10",
    "outputId": "bedc40f0-42ff-4c49-c437-52538b1ad54d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eilaarich-landkof-stanford/miniconda3/envs/transformers/lib/python3.8/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import ViTFeatureExtractor\n",
    "\n",
    "model_name_or_path = 'google/vit-base-patch16-224-in21k'\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AlCd0biJ8UhI",
    "outputId": "762cf714-3b54-4903-8cb8-2a96157c1348"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViTFeatureExtractor {\n",
       "  \"do_normalize\": true,\n",
       "  \"do_rescale\": true,\n",
       "  \"do_resize\": true,\n",
       "  \"image_mean\": [\n",
       "    0.5,\n",
       "    0.5,\n",
       "    0.5\n",
       "  ],\n",
       "  \"image_processor_type\": \"ViTFeatureExtractor\",\n",
       "  \"image_std\": [\n",
       "    0.5,\n",
       "    0.5,\n",
       "    0.5\n",
       "  ],\n",
       "  \"resample\": 2,\n",
       "  \"rescale_factor\": 0.00392156862745098,\n",
       "  \"size\": {\n",
       "    \"height\": 224,\n",
       "    \"width\": 224\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "G9Tb_ZANCwch"
   },
   "outputs": [],
   "source": [
    "def augmentation_fn(image):\n",
    "  import torchvision.transforms as T\n",
    "  transform = T.Compose([\n",
    "    T.RandomHorizontalFlip(p=0.5),  # 50% chance of horizontal flip\n",
    "    T.RandomVerticalFlip(p=0.5),    # 50% chance of vertical flip\n",
    "    # T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Random color jitter\n",
    "    T.RandomRotation(degrees=10),   # Random rotation up to 10 degrees\n",
    "  ])\n",
    "\n",
    "  augmented_image = transform(image)\n",
    "  return augmented_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_path': '/Users/eilaarich-landkof-stanford/Downloads/train_validation_test_2023_08_14_20_18/train/nonprogressor/3119_vector_image_row_1023_col310.jpg', 'labels': 'nonprogressor', 'pil_image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=224x224 at 0x15C4C97C0>}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOAAAADgCAIAAACVT/22AAAC4UlEQVR4nO3by5aiMBQFUED//4/FGmR1VjoQBA0YcO9RayOh4iGPS1XXAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABcVF/tRP22Uz2fz1pNc2H3b18A51AagPYeaIZdzw4fMsWz1jDMD2fjOO7YaK0TbQ3c1kDzm0zxNM0miVxpcitN5btOhmcK6Lc2km8vr8MHs5ef+6nl+38BzTo0vpO+v9A7pf8qfTHfChwnYg1K0wSUpgkoTRNQmiagNO1MZSZ2FSs24zjOVm9qlcmGYXg+n2lVdRiGvu8fj8e03aYDervduqSDtpaxavmwfBZfbj1PqZ661cJ1viwd7mG2udI13Ltyh85++IBn6H3fZ1+JyujeXt5FdYXxOLQV/lHKVaMjaPoDdAK6j+qPuD5pd2kEbU12rdJ5gG9N9y+1u4tvraeuJx3JgsPm97Td7M1MuwGN/ObofsJS6vgeThedyzdGi1N8MO04Y+rFrKlOtBjQWAyLP8Bhs8/PGsdxunfJqjehfhnfT+ums+cMh4UaZ3gZjowvS7u0tN0WA9r9u+LH47Hm4OrZXVl3/LAwub5GkR2wEJQQozQQMQfToASxLN+mmTpotOsfQy20u1CTZ0G20YnrvFqdmW3zj5nZGh1BWVAKyuzUuUeG0pF72fSG2XoxAnodWS0zfa79eVDiZ7OVyUJMS2vZTS3eux3WcCuZx982fZYRMjcNUFcOytb+3/QMvZYT1EHJlIJyQIA2PeRLb4y3H6t+cwSlrulvP8X9++zUf4rv3Rr0atY8P5xKj9wU3IWDZ4fbU9wVFxEqiy0XEflp0snJiGx1dvHVpHVHahFQ+BmmeBoijgcwxb/PohMAAAAAAAAAAAAAXvgDdirRKCK/3QgAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=224x224>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "print(ds['train'][0])\n",
    "aug_example = augmentation_fn(ds['train'][0]['pil_image'])\n",
    "aug_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nAslJflg9Bed",
    "outputId": "cf63bfef-698c-4218-e3e2-86cd498f8411"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name_prefix is norm_False_scl_False_resz_False_aug_T\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "do_normalize=False\n",
    "do_rescale=False\n",
    "do_resize=False\n",
    "model_name_prefix = \"norm_{}_scl_{}_resz_{}_aug_T\".format(do_normalize,do_rescale,do_resize)\n",
    "print(\"model_name_prefix is {}\".format(model_name_prefix))\n",
    "\n",
    "prepared_ds={}\n",
    "def transform(example_batch):\n",
    "  from PIL import Image\n",
    "    # Take a list of PIL images and turn them to pixel values\n",
    "  # print(\"example_batch is {}\".format(example_batch))\n",
    "  inputs = feature_extractor([Image.open(x) for x in example_batch['image_path']],\n",
    "                              do_normalize=do_normalize,\n",
    "                              do_rescale=do_rescale,\n",
    "                              do_resize=do_resize,\n",
    "                              augmentation_fn=augmentation_fn,\n",
    "                              return_tensors='pt')\n",
    "\n",
    "  # Extract PIL image objects from example_batch - need to be faster\n",
    "  # pil_images = [np.array(sample['pil_image']) for sample in example_batch]\n",
    "  # inputs = feature_extractor(pil_images,\n",
    "  #                            do_normalize=do_normalize,\n",
    "  #                            do_rescale=do_rescale,\n",
    "  #                            do_resize=do_resize,\n",
    "  #                            augmentation_fn=augmentation_fn,\n",
    "  #                            return_tensors='pt')\n",
    "\n",
    "\n",
    "    # Don't forget to include the labels!\n",
    "  # inputs['labels'] = [class_labels.str2int(sample['labels']) for sample in example_batch]\n",
    "  inputs['labels'] = example_batch['labels']\n",
    "  return inputs\n",
    "\n",
    "for val in [\"train\",\"validation\",\"test\"]:\n",
    "  prepared_ds[val] = ds[val].with_transform(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "v5fIwIo19IJH"
   },
   "outputs": [],
   "source": [
    "# prepared_ds['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "1KxxD_Qg9K2V"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def collate_fn(batch):\n",
    "  return {\n",
    "        # 'pixel_values': torch.stack([x['pil_image'] for x in batch]),\n",
    "        'pixel_values': torch.stack([x['pixel_values'] for x in batch]),\n",
    "        # 'labels': torch.tensor([x['labels'] for x in batch])\n",
    "        'labels': torch.tensor([class_labels.str2int(x['labels']) for x in batch])\n",
    "    }\n",
    "\n",
    "    # class_labels.str2int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "MRIhFyCB9QQS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j6/2st107dn1vl18n57n7y_2v240000gn/T/ipykernel_40969/2425197347.py:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ü§ó Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"accuracy\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "def compute_metrics(p):\n",
    "    return metric.compute(predictions=np.argmax(p.predictions, axis=1), references=p.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oDNaburKEA_U",
    "outputId": "100d19cb-72f6-4e40-9a7e-e92568caf5f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nonprogressor', 'progressor']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_labels.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "IZifGvUTTh6l"
   },
   "outputs": [],
   "source": [
    "\n",
    "# for CPU:\n",
    "# !pip install transformers[torch]\n",
    "# restart\n",
    "# !pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kwAn4E3J9SIW",
    "outputId": "4a54fb94-6f45-4f46-c22a-c4fd90f155e3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import ViTForImageClassification\n",
    "\n",
    "labels = class_labels.names #ds['train'].features['labels'].names\n",
    "\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    num_labels=len(labels),\n",
    "    id2label={str(i): c for i, c in enumerate(labels)},\n",
    "    label2id={c: str(i) for i, c in enumerate(labels)}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "g1upvHM1Od_s",
    "outputId": "bb5f75d4-3d72-4a53-96a0-547f3656f7fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023_08_14_17_31_48'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a date-time string\n",
    "from datetime import datetime\n",
    "current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "current_datetime = current_datetime.replace(\"-\",\"_\")\n",
    "current_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "id": "0CHxNIZ1TgDS",
    "outputId": "0a18767b-b40a-48be-a602-405cb7026be6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name is _lr_0_005_epochs_50_batch_size_16\n",
      "model_output_dir is /Users/eilaarich-landkof-stanford/Downloads/train_validation_test_2023_08_14_20_18/model_output_dir/norm_False_scl_False_resz_False_aug_T_lr_0_005_epochs_50_batch_size_16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/eilaarich-landkof-stanford/Downloads/train_validation_test_2023_08_14_20_18/tensorboard/2023_08_14_17_31_48_lr_0_005_epochs_50_batch_size_16'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, IntervalStrategy\n",
    "\n",
    "# from sklearn.utils.class_weight import compute_class_weight\n",
    "# # Create callbacks\n",
    "# train_dataclass_weights=class_weights,\n",
    "#\n",
    "\n",
    "lr = 5e-3\n",
    "num_train_epochs = 50\n",
    "batch_size = 16\n",
    "early_stopping_callback = EarlyStoppingCallback(early_stopping_patience=5)\n",
    "# class_weights = compute_class_weight('balanced', classes=[0, 1], y=prepared_ds[\"train\"][\"labels\"])\n",
    "model_name = \"_lr_{}_epochs_{}_batch_size_{}\".format(str(lr).replace(\".\",\"_\"),num_train_epochs,batch_size)\n",
    "print(\"model_name is {}\".format(model_name))\n",
    "# evaluation_strategy = \"epoch\"\n",
    "# optimizers\n",
    "# callbacks\n",
    "model_output_dir = os.path.join(rgb_images_path, \"model_output_dir\",model_name_prefix+model_name)\n",
    "print(\"model_output_dir is {}\".format(model_output_dir))\n",
    "\n",
    "os.makedirs(model_output_dir,exist_ok=True)\n",
    "model_output_dir\n",
    "\n",
    "tensorboard_log = os.path.join(rgb_images_path, \"tensorboard\",current_datetime+model_name)\n",
    "os.makedirs(tensorboard_log,exist_ok=True)\n",
    "tensorboard_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "yxWtYLBdWzMT",
    "outputId": "45a63a4a-4b5d-4460-a660-1b8a1a57cdab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/eilaarich-landkof-stanford/Downloads/train_validation_test_2023_08_14_20_18/tensorboard/2023_08_14_17_31_48_lr_0_005_epochs_50_batch_size_16'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorboard_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "mmmWoDbLEaGI"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "  output_dir=model_output_dir,\n",
    "  per_device_train_batch_size=batch_size,\n",
    "  evaluation_strategy = \"epoch\",\n",
    "  logging_strategy = \"epoch\",\n",
    "  save_strategy = \"epoch\",\n",
    "  num_train_epochs=num_train_epochs,\n",
    "  save_steps=100,\n",
    "  eval_steps = 50,\n",
    "  logging_steps=10,\n",
    "  learning_rate=lr,\n",
    "  save_total_limit=5,\n",
    "  remove_unused_columns=False,\n",
    "  push_to_hub=False,\n",
    "  report_to='tensorboard',\n",
    "  load_best_model_at_end=True,\n",
    "  # fp16=False,  # Disable mixed precision training. The True had error issues\n",
    "  fp16_opt_level=\"O2\",  # Specify optimization level\n",
    "  logging_dir=tensorboard_log, # Set the logging directory\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xKI-oRZHz_hD",
    "outputId": "f16a1700-2380-4cca-89cd-ac54caf97c4a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset({\n",
       "     features: ['image_path', 'labels', 'pil_image'],\n",
       "     num_rows: 30519\n",
       " }),\n",
       " 'validation': Dataset({\n",
       "     features: ['image_path', 'labels', 'pil_image'],\n",
       "     num_rows: 6539\n",
       " }),\n",
       " 'test': Dataset({\n",
       "     features: ['image_path', 'labels', 'pil_image'],\n",
       "     num_rows: 6542\n",
       " })}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "3gaGlHFCEfoP"
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=prepared_ds[\"train\"],\n",
    "    eval_dataset=prepared_ds[\"validation\"],\n",
    "    callbacks = [early_stopping_callback],\n",
    "    tokenizer=feature_extractor,\n",
    "    # train_dataclass_weights=class_weights,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "id": "S2K57vfFH0zc",
    "outputId": "ed0561ed-7763-4d12-d1ea-53408eee0504"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eilaarich-landkof-stanford/miniconda3/envs/transformers/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='459' max='95400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  459/95400 22:14 < 76:58:58, 0.34 it/s, Epoch 0.24/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_results = trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fzP1pDgSOs59"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jfFTAiUQu4ck"
   },
   "outputs": [],
   "source": [
    "trainer.save_model()\n",
    "trainer.log_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KNrJHsTEy4vh"
   },
   "outputs": [],
   "source": [
    "prepared_ds['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3stKYrWBH4dW"
   },
   "outputs": [],
   "source": [
    "metrics = trainer.evaluate(prepared_ds['test'])\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sVsRPOwqH8tm"
   },
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    \"finetuned_from\": model.config._name_or_path,\n",
    "    \"tasks\": \"image-classification\",\n",
    "    \"dataset\": 'dcis-eila',\n",
    "    \"tags\": ['image-classification'],\n",
    "}\n",
    "\n",
    "if training_args.push_to_hub:\n",
    "    trainer.push_to_hub('üçª cheers', **kwargs)\n",
    "else:\n",
    "    trainer.create_model_card(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sfsyFURk18Fc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JkadroVuOyWV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZPW3s-6JOyjA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rxP2o14hOyo4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOwMxzh84Gzd7Zlj+JxWJrH",
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2f08a82ee9954559a8d33b7ea328691f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3377058e433b4fa9a08b58c6bd50d37e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d97ec4ab607e4f18b02ce5552227ba7b",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_ba58cb5ee22147bda7f3de33fe53a997",
      "value": "Downloading (‚Ä¶)rocessor_config.json: 100%"
     }
    },
    "57ae87708adf4568aa754f712abd4290": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7aed4615ee9e4830aa18f7ff38ad5c3e",
      "max": 160,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d1e0e92df70242408234c38ec0522452",
      "value": 160
     }
    },
    "5cffb7213aa546eb8b976a32b2b2573f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3377058e433b4fa9a08b58c6bd50d37e",
       "IPY_MODEL_57ae87708adf4568aa754f712abd4290",
       "IPY_MODEL_edb9e3aaf4414993a323284758afd5ed"
      ],
      "layout": "IPY_MODEL_2f08a82ee9954559a8d33b7ea328691f"
     }
    },
    "7aed4615ee9e4830aa18f7ff38ad5c3e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7bb5710864e34c399a31d067d493eca5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba58cb5ee22147bda7f3de33fe53a997": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bef3d30a0d7a41be8b0292e9fce2d6d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d1e0e92df70242408234c38ec0522452": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d97ec4ab607e4f18b02ce5552227ba7b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "edb9e3aaf4414993a323284758afd5ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7bb5710864e34c399a31d067d493eca5",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_bef3d30a0d7a41be8b0292e9fce2d6d2",
      "value": " 160/160 [00:00&lt;00:00, 9.32kB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
