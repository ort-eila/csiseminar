{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO1O7SUGOgg7KpxSMQnOflw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "74a4a380cbed446aae4e7353ed5a63a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_15c7ef4b9dc648379ca25d95d9ffc906",
              "IPY_MODEL_f4fbe32ecf4c4b3f9c00c3712491dd8e",
              "IPY_MODEL_eff2978163d44d62b1177a121e218721"
            ],
            "layout": "IPY_MODEL_895508202b8d49fbb3eac412f40f8242"
          }
        },
        "15c7ef4b9dc648379ca25d95d9ffc906": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95858e7597f0491f854226e2cf919a14",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0a2ab44768bc4b74b0f912c9e6ca3353",
            "value": "Downloading (‚Ä¶)rocessor_config.json: 100%"
          }
        },
        "f4fbe32ecf4c4b3f9c00c3712491dd8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1ecfad044244cb3b17f1d1867bf2765",
            "max": 160,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d22b4ac402c84320b1885f12cb103ae6",
            "value": 160
          }
        },
        "eff2978163d44d62b1177a121e218721": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_665f7b0a4a094d74957c65e836f77568",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d291a4a2fd044f008a3ead1803a082bd",
            "value": " 160/160 [00:00&lt;00:00, 7.21kB/s]"
          }
        },
        "895508202b8d49fbb3eac412f40f8242": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95858e7597f0491f854226e2cf919a14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a2ab44768bc4b74b0f912c9e6ca3353": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1ecfad044244cb3b17f1d1867bf2765": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d22b4ac402c84320b1885f12cb103ae6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "665f7b0a4a094d74957c65e836f77568": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d291a4a2fd044f008a3ead1803a082bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ort-eila/csiseminar/blob/main/project/step4_load_dataset_vit_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install transformers\n",
        "# !pip install --upgrade transformers\n",
        "# !pip install datasets\n",
        "# !pip install --upgrade datasets\n",
        "\n",
        "# # for CPU:\n",
        "# !pip install transformers[torch]\n",
        "# # restart\n",
        "# !pip install tensorboard\n"
      ],
      "metadata": {
        "id": "OldUIqyzUm8d"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VA9wr4JSTHXK",
        "outputId": "51670906-7764-470d-ebb9-676e6139d66c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "rgb_images_path = \"/content/gdrive/MyDrive/Seminar/project/immune_310_project/dataset/JPG_RGB_224_224/train_validation_test\""
      ],
      "metadata": {
        "id": "yCBBOmNSTNOr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "\n",
        "print(\"datasets version:\", datasets.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdaEVkvJbAVG",
        "outputId": "3e5a5d63-cf1b-4108-df4e-52548ba6f8a3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datasets version: 2.14.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import ClassLabel\n",
        "\n",
        "class_labels = ClassLabel(names=[\"nonprogressor\", \"progressor\"])\n"
      ],
      "metadata": {
        "id": "136y8YShdzqg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets.io.abc import Dataset\n",
        "\n",
        "ds={}\n",
        "for val in [\"train\",\"validation\",\"test\"]:\n",
        "  ds_with_pil_images_fld = os.path.join(rgb_images_path,'ds_with_pil_images',val)   # Output metadata JSON file name\n",
        "  print(\"ds_with_pil_images_fld is {}\".format(ds_with_pil_images_fld))\n",
        "  ds[val] = Dataset.load_from_disk(ds_with_pil_images_fld)\n",
        "  print(\"Datasets saved to disk with PIL images. \",val)\n",
        "# will be used by step 4"
      ],
      "metadata": {
        "id": "xvBd6fc9a4Jd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba91d8be-07f8-4a45-c0b3-b699689d809d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ds_with_pil_images_fld is /content/gdrive/MyDrive/Seminar/project/immune_310_project/dataset/JPG_RGB_224_224/train_validation_test/ds_with_pil_images/train\n",
            "Datasets saved to disk with PIL images.  train\n",
            "ds_with_pil_images_fld is /content/gdrive/MyDrive/Seminar/project/immune_310_project/dataset/JPG_RGB_224_224/train_validation_test/ds_with_pil_images/validation\n",
            "Datasets saved to disk with PIL images.  validation\n",
            "ds_with_pil_images_fld is /content/gdrive/MyDrive/Seminar/project/immune_310_project/dataset/JPG_RGB_224_224/train_validation_test/ds_with_pil_images/test\n",
            "Datasets saved to disk with PIL images.  test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds['train']"
      ],
      "metadata": {
        "id": "LoWu2c5WerSS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fd77c5b-c0be-41ea-dca0-df951c72e5e9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['image_path', 'labels', 'pil_image'],\n",
              "    num_rows: 3365\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "from IPython.display import display\n",
        "\n",
        "\n",
        "# Access an example and its PIL image\n",
        "ex = ds['train'][0]\n",
        "print(\"Example:\", ex)\n",
        "\n",
        "# Display the PIL image\n",
        "display(ex[\"pil_image\"])\n",
        "\n",
        "# Convert PIL image to NumPy array\n",
        "image_array = np.array(ex[\"pil_image\"])\n",
        "\n",
        "# Display image array shape and pixel values\n",
        "print(\"Image array shape:\", image_array.shape)\n",
        "print(\"Min pixel value:\", np.min(image_array))\n",
        "print(\"Max pixel value:\", np.max(image_array))"
      ],
      "metadata": {
        "id": "mh2GkRS8arDJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "9b151fcd-e855-4be8-83b2-0851c105ee84"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example: {'image_path': '/content/gdrive/MyDrive/Seminar/project/immune_310_project/dataset/JPG_RGB_224_224/train_validation_test/train/progressor/3105_rgb_image_img118_row1023_col1023_rgb_values_counter5970944.jpg', 'labels': 'progressor', 'pil_image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=224x224 at 0x7EF2B04F9C60>}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=224x224>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOAAAADgCAIAAACVT/22AAABJUlEQVR4nO3csQ3DMBAEQb37L9oNyDbAgFoaMxVcsPFdFwAAAAAAAAAAAAAAAAAAAPCcmZmZp1f8dsrOzV5PD4BvBEqaQEkTKGkCJU2gpAkUAAAAAAAAAAAAAAAAAAAAAEpuv04XDlA9i5AmUNIESppASRMoaQIlTaAAAAAAAAAAAAAAAAAAAAAAfDAzC7eU+52yczPPIqQJlDSBkiZQ0gRKmkBJEygAAAAAAAAAAAAAAAAAAAAAlNx+nS4coHoWIU2gpAmUNIGSJlDSBEqaQAEAAAAAAAAAAAAAAAAAAAA43Mws3Gf+Pc8ipAmUNIGSJlDSBEqaQEkTKAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQMwbj8wAcU4LNzcAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image array shape: (224, 224, 3)\n",
            "Min pixel value: 0\n",
            "Max pixel value: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ds['train'][0]['labels']\n",
        "labels"
      ],
      "metadata": {
        "id": "eq6C5gCpedTj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "93f07b4f-64e7-45f4-a733-471af53be6d5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'progressor'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_labels"
      ],
      "metadata": {
        "id": "u2kaknVs8JUj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2362b81-d934-4f34-f86f-754fba8b5bcb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ClassLabel(names=['nonprogressor', 'progressor'], id=None)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_labels.str2int(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsxeO-Ut6MHm",
        "outputId": "e9f83655-0dfb-462c-b5d7-4e8c9d05a757"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import ViTFeatureExtractor\n",
        "\n",
        "model_name_or_path = 'google/vit-base-patch16-224-in21k'\n",
        "feature_extractor = ViTFeatureExtractor.from_pretrained(model_name_or_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "74a4a380cbed446aae4e7353ed5a63a6",
            "15c7ef4b9dc648379ca25d95d9ffc906",
            "f4fbe32ecf4c4b3f9c00c3712491dd8e",
            "eff2978163d44d62b1177a121e218721",
            "895508202b8d49fbb3eac412f40f8242",
            "95858e7597f0491f854226e2cf919a14",
            "0a2ab44768bc4b74b0f912c9e6ca3353",
            "a1ecfad044244cb3b17f1d1867bf2765",
            "d22b4ac402c84320b1885f12cb103ae6",
            "665f7b0a4a094d74957c65e836f77568",
            "d291a4a2fd044f008a3ead1803a082bd"
          ]
        },
        "id": "n_Q_au_o7x10",
        "outputId": "ad0fb715-176e-4e31-e7f8-d7a7db24daa5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (‚Ä¶)rocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "74a4a380cbed446aae4e7353ed5a63a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlCd0biJ8UhI",
        "outputId": "daefc20e-7612-4b02-f063-4d25684e386b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ViTFeatureExtractor {\n",
              "  \"do_normalize\": true,\n",
              "  \"do_rescale\": true,\n",
              "  \"do_resize\": true,\n",
              "  \"image_mean\": [\n",
              "    0.5,\n",
              "    0.5,\n",
              "    0.5\n",
              "  ],\n",
              "  \"image_processor_type\": \"ViTFeatureExtractor\",\n",
              "  \"image_std\": [\n",
              "    0.5,\n",
              "    0.5,\n",
              "    0.5\n",
              "  ],\n",
              "  \"resample\": 2,\n",
              "  \"rescale_factor\": 0.00392156862745098,\n",
              "  \"size\": {\n",
              "    \"height\": 224,\n",
              "    \"width\": 224\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds['train']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkBEycm8TSZs",
        "outputId": "6e911eaf-e7cc-4656-b92c-56b49ded199c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['image_path', 'labels', 'pil_image'],\n",
              "    num_rows: 3365\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ex"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VogrBmdGDnux",
        "outputId": "824104a5-2351-4b0f-da04-81a309bb796d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'image_path': '/content/gdrive/MyDrive/Seminar/project/immune_310_project/dataset/JPG_RGB_224_224/train_validation_test/train/progressor/3105_rgb_image_img118_row1023_col1023_rgb_values_counter5970944.jpg',\n",
              " 'labels': 'progressor',\n",
              " 'pil_image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=224x224>}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DEBUG\n",
        "ex = ds['train'][400]\n",
        "# image = ex['pil_image']\n",
        "image_path = ex['image_path']\n",
        "pil_image = Image.open(image_path)\n",
        "feature_extractor(pil_image, return_tensors='pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8F2SK-K8ieM",
        "outputId": "eff10dc2-b91c-4d50-ba36-e954f947be00"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'pixel_values': tensor([[[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          ...,\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
              "\n",
              "         [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          ...,\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
              "\n",
              "         [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          ...,\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.]]]])}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ONLY FOR DEBUG\n",
        "# def process_example(example):\n",
        "#   inputs = feature_extractor(example['pil_image'], return_tensors='pt')\n",
        "#   inputs['labels'] = example['labels']\n",
        "#   return inputs\n",
        "def process_example(example):\n",
        "  # image_path = example['image_path']\n",
        "  # pil_image = Image.open(image_path)\n",
        "  # np.array(example[\"pil_image\"])\n",
        "  feature_extractor(np.array(example[\"pil_image\"]), return_tensors='pt')\n",
        "  inputs = feature_extractor(pil_image, return_tensors='pt')\n",
        "  inputs['labels'] = class_labels.str2int(example['labels'])\n",
        "  return inputs"
      ],
      "metadata": {
        "id": "c1RsVYht8vrE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_example = process_example(ds['train'][0])\n",
        "in_example"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTfoqgv-9BLF",
        "outputId": "1a75cb86-f2d8-48ea-acd9-6a3f4f567f08"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'pixel_values': tensor([[[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          ...,\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
              "\n",
              "         [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          ...,\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
              "\n",
              "         [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          ...,\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.]]]]), 'labels': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(in_example['pixel_values'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsaXBgmqC4tV",
        "outputId": "c680e4db-3398-4ec6-fddf-e1a38b117c21"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# feature_extractor([x for x in example_batch['pil_image']], return_tensors='pt')"
      ],
      "metadata": {
        "id": "G9Tb_ZANCwch"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepared_ds={}\n",
        "# def transform(example_batch):\n",
        "#     # Take a list of PIL images and turn them to pixel values\n",
        "#     inputs = feature_extractor([x for x in example_batch['pil_image']], return_tensors='pt')\n",
        "\n",
        "#     # Don't forget to include the labels!\n",
        "#     inputs['labels'] = example_batch['labels']\n",
        "#     return inputs\n",
        "\n",
        "# for val in [\"train\",\"validation\",\"test\"]:\n",
        "#   prepared_ds[val] = ds[val].with_transform(transform)\n",
        "\n",
        "prepared_ds={}\n",
        "def transform(example_batch):\n",
        "    # Take a list of PIL images and turn them to pixel values\n",
        "    inputs = feature_extractor([Image.open(x) for x in example_batch['image_path']], return_tensors='pt')\n",
        "\n",
        "    # Don't forget to include the labels!\n",
        "    inputs['labels'] = example_batch['labels']\n",
        "    return inputs\n",
        "\n",
        "for val in [\"train\",\"validation\",\"test\"]:\n",
        "  prepared_ds[val] = ds[val].with_transform(transform)"
      ],
      "metadata": {
        "id": "nAslJflg9Bed"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prepared_ds['train']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5fIwIo19IJH",
        "outputId": "106409d3-0278-4ac3-e76d-94e21afd16ed"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['image_path', 'labels', 'pil_image'],\n",
              "    num_rows: 3365\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def collate_fn(batch):\n",
        "  return {\n",
        "        # 'pixel_values': torch.stack([x['pil_image'] for x in batch]),\n",
        "        'pixel_values': torch.stack([x['pixel_values'] for x in batch]),\n",
        "        'labels': torch.tensor([class_labels.str2int(x['labels']) for x in batch])\n",
        "    }\n",
        "\n",
        "    # class_labels.str2int\n"
      ],
      "metadata": {
        "id": "1KxxD_Qg9K2V"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from datasets import load_metric\n",
        "\n",
        "metric = load_metric(\"accuracy\")\n",
        "def compute_metrics(p):\n",
        "    return metric.compute(predictions=np.argmax(p.predictions, axis=1), references=p.label_ids)"
      ],
      "metadata": {
        "id": "MRIhFyCB9QQS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51acd3c1-ba76-495e-ff07-1ebac5744112"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-3044fb6e3895>:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ü§ó Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric(\"accuracy\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_labels.names"
      ],
      "metadata": {
        "id": "oDNaburKEA_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# for CPU:\n",
        "# !pip install transformers[torch]\n",
        "# restart\n",
        "# !pip install tensorboard"
      ],
      "metadata": {
        "id": "IZifGvUTTh6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import ViTForImageClassification\n",
        "\n",
        "labels = class_labels.names #ds['train'].features['labels'].names\n",
        "\n",
        "model = ViTForImageClassification.from_pretrained(\n",
        "    model_name_or_path,\n",
        "    num_labels=len(labels),\n",
        "    id2label={str(i): c for i, c in enumerate(labels)},\n",
        "    label2id={c: str(i) for i, c in enumerate(labels)}\n",
        ")"
      ],
      "metadata": {
        "id": "kwAn4E3J9SIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a date-time string\n",
        "from datetime import datetime\n",
        "current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "current_datetime"
      ],
      "metadata": {
        "id": "g1upvHM1Od_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensorboard_log = os.path.join(rgb_images_path, \"tensorboard\",current_datetime)\n",
        "os.makedirs(tensorboard_log,exist_ok=True)\n",
        "tensorboard_log"
      ],
      "metadata": {
        "id": "c5VP5A3aOGWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 5e-5\n",
        "num_train_epochs = 20\n",
        "batch_size = 16\n",
        "# evaluation_strategy = \"epoch\"\n",
        "# optimizers\n",
        "# callbacks\n",
        "model_output_dir = os.path.join(rgb_images_path, \"model_output_dir\",\"lr_{}_epochs_{}_batch_size_{}\".format(lr,num_train_epochs,batch_size))\n",
        "os.makedirs(model_output_dir,exist_ok=True)\n",
        "model_output_dir"
      ],
      "metadata": {
        "id": "0CHxNIZ1TgDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "  output_dir=model_output_dir,\n",
        "  per_device_train_batch_size=batch_size,\n",
        "  evaluation_strategy = IntervalStrategy.STEPS\n",
        "  logging_strategy = \"epoch\"\n",
        "  save_strategy = \"epoch\"\n",
        "  num_train_epochs=num_train_epochs,\n",
        "  save_steps=100,\n",
        "  eval_steps = 50,\n",
        "  logging_steps=10,\n",
        "  learning_rate=lr,\n",
        "  save_total_limit=5,\n",
        "  remove_unused_columns=False,\n",
        "  push_to_hub=False,\n",
        "  report_to='tensorboard',\n",
        "  load_best_model_at_end=True,\n",
        "  # fp16=False,  # Disable mixed precision training. The True had error issues\n",
        "  fp16_opt_level=\"O2\",  # Specify optimization level\n",
        "  logging_dir=tensorboard_log, # Set the logging directory\n",
        ")\n"
      ],
      "metadata": {
        "id": "mmmWoDbLEaGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prepared_ds"
      ],
      "metadata": {
        "id": "xKI-oRZHz_hD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# type(prepared_ds['train']['pil_image'])"
      ],
      "metadata": {
        "id": "Sa1jCPbh07g-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=collate_fn,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=prepared_ds[\"train\"],\n",
        "    eval_dataset=prepared_ds[\"validation\"],\n",
        "    callbacks = [EarlyStoppingCallback(early_stopping_patience=5)]\n",
        "    tokenizer=feature_extractor,\n",
        ")"
      ],
      "metadata": {
        "id": "3gaGlHFCEfoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_results = trainer.train()\n"
      ],
      "metadata": {
        "id": "S2K57vfFH0zc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fzP1pDgSOs59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model()\n",
        "trainer.log_metrics(\"train\", train_results.metrics)\n",
        "trainer.save_metrics(\"train\", train_results.metrics)\n",
        "trainer.save_state()"
      ],
      "metadata": {
        "id": "jfFTAiUQu4ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prepared_ds['test']"
      ],
      "metadata": {
        "id": "KNrJHsTEy4vh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = trainer.evaluate(prepared_ds['test'])\n",
        "trainer.log_metrics(\"eval\", metrics)\n",
        "trainer.save_metrics(\"eval\", metrics)"
      ],
      "metadata": {
        "id": "3stKYrWBH4dW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kwargs = {\n",
        "    \"finetuned_from\": model.config._name_or_path,\n",
        "    \"tasks\": \"image-classification\",\n",
        "    \"dataset\": 'dcis-eila',\n",
        "    \"tags\": ['image-classification'],\n",
        "}\n",
        "\n",
        "if training_args.push_to_hub:\n",
        "    trainer.push_to_hub('üçª cheers', **kwargs)\n",
        "else:\n",
        "    trainer.create_model_card(**kwargs)"
      ],
      "metadata": {
        "id": "sVsRPOwqH8tm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sfsyFURk18Fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JkadroVuOyWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZPW3s-6JOyjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rxP2o14hOyo4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}